# Toxic Comment Classification

**Requirements**

* torchtext
* pytorch>=0.3.0
* tqdm
* spacy

**Download data from [https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data) and extract it under data/**

**Train and evaluate model**
```shell
python main.py
```
upload the result to the kaggle to see the result.
